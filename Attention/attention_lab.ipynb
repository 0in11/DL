{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"bJm88P18Mx4b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716967181422,"user_tz":-540,"elapsed":2843,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"eb99b199-4de4-4587-fa1a-3519f9e5f350"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir('drive/MyDrive/DL202010821/Attention')\n","\n","%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","source":["import os\n","import shutil\n","import zipfile\n","\n","import pandas as pd\n","import tensorflow as tf\n","import urllib3\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical"],"metadata":{"id":"53s2Qur-M06T","executionInfo":{"status":"ok","timestamp":1716967189250,"user_tz":-540,"elapsed":4409,"user":{"displayName":"헤헤","userId":"03480456663930627726"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["lines = pd.read_csv('dataset/fra.txt', names=['src', 'tar', 'lic'], sep='\\t')\n","del lines['lic']\n","print('전체 샘플의 개수 :',len(lines))"],"metadata":{"id":"03HWuIAgM6Ob","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716967192794,"user_tz":-540,"elapsed":1696,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"c39d868d-76ba-4c13-850d-6ccb14178976"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 샘플의 개수 : 232736\n"]}]},{"cell_type":"code","source":["lines = lines.loc[:, 'src':'tar']\n","lines = lines[0:30000] # 3만개만 사용\n","lines.sample(10)"],"metadata":{"id":"BpsaTkOVM8JJ","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"ok","timestamp":1716967192794,"user_tz":-540,"elapsed":6,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"a205283c-9cc2-429d-a633-75cdaaf377ba"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                      src                          tar\n","5010        Have a snack.           Prenez un en-cas !\n","12153     Is this common?              C'est courant ?\n","5715        I'm so sorry.  Je suis tellement désolée !\n","7065        You're upset.            Tu es contrariée.\n","1230           I'm broke.              Je suis fauché.\n","23615   Tom isn't a snob.          Tom n'est pas snob.\n","2934         Be prepared.          Tenez-vous prêtes !\n","27122  I lost my glasses.     J'ai perdu mes lunettes.\n","28734  No one was crying.        Personne ne pleurait.\n","20358   How tall you are!          Comme tu es grand !"],"text/html":["\n","  <div id=\"df-132c0bc4-0470-4115-8d4d-6216cfe7b8ff\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>src</th>\n","      <th>tar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5010</th>\n","      <td>Have a snack.</td>\n","      <td>Prenez un en-cas !</td>\n","    </tr>\n","    <tr>\n","      <th>12153</th>\n","      <td>Is this common?</td>\n","      <td>C'est courant ?</td>\n","    </tr>\n","    <tr>\n","      <th>5715</th>\n","      <td>I'm so sorry.</td>\n","      <td>Je suis tellement désolée !</td>\n","    </tr>\n","    <tr>\n","      <th>7065</th>\n","      <td>You're upset.</td>\n","      <td>Tu es contrariée.</td>\n","    </tr>\n","    <tr>\n","      <th>1230</th>\n","      <td>I'm broke.</td>\n","      <td>Je suis fauché.</td>\n","    </tr>\n","    <tr>\n","      <th>23615</th>\n","      <td>Tom isn't a snob.</td>\n","      <td>Tom n'est pas snob.</td>\n","    </tr>\n","    <tr>\n","      <th>2934</th>\n","      <td>Be prepared.</td>\n","      <td>Tenez-vous prêtes !</td>\n","    </tr>\n","    <tr>\n","      <th>27122</th>\n","      <td>I lost my glasses.</td>\n","      <td>J'ai perdu mes lunettes.</td>\n","    </tr>\n","    <tr>\n","      <th>28734</th>\n","      <td>No one was crying.</td>\n","      <td>Personne ne pleurait.</td>\n","    </tr>\n","    <tr>\n","      <th>20358</th>\n","      <td>How tall you are!</td>\n","      <td>Comme tu es grand !</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-132c0bc4-0470-4115-8d4d-6216cfe7b8ff')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-132c0bc4-0470-4115-8d4d-6216cfe7b8ff button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-132c0bc4-0470-4115-8d4d-6216cfe7b8ff');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-92cc1f8c-0e6e-4071-891d-e610044fdd44\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-92cc1f8c-0e6e-4071-891d-e610044fdd44')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-92cc1f8c-0e6e-4071-891d-e610044fdd44 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"lines\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"src\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"No one was crying.\",\n          \"Is this common?\",\n          \"Tom isn't a snob.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tar\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Personne ne pleurait.\",\n          \"C'est courant\\u00a0?\",\n          \"Tom n'est pas snob.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["lines.tar = lines.tar.apply(lambda x : '\\t '+ x + ' \\n')\n","lines.sample(10)"],"metadata":{"id":"Buq3e7a7M9Oe","colab":{"base_uri":"https://localhost:8080/","height":363},"executionInfo":{"status":"ok","timestamp":1716967192795,"user_tz":-540,"elapsed":6,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"04af5a13-dc19-463d-d4f4-090e93b0894a"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                      src                                tar\n","10636     Do as you like.    \\t Fais comme il te plaira ! \\n\n","10795     Don't waste it.          \\t Ne le gaspille pas. \\n\n","21889   Is this your car?       \\t Est-ce votre voiture ? \\n\n","12157     Is this for me?  \\t Est-ce que c'est pour moi ? \\n\n","24487   What's your name?      \\t Comment tu t’appelles ? \\n\n","29334  That's pretty big.           \\t C'est plutôt gros. \\n\n","19037    You're generous.              \\t Tu es généreux. \\n\n","12172     It doesn't fit.          \\t Ça ne convient pas. \\n\n","1123           I hate it.               \\t Je déteste ça. \\n\n","22933   That's too risky.           \\t C'est trop risqué. \\n"],"text/html":["\n","  <div id=\"df-0a870b78-44b8-4dce-abef-29d1d055dc55\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>src</th>\n","      <th>tar</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10636</th>\n","      <td>Do as you like.</td>\n","      <td>\\t Fais comme il te plaira ! \\n</td>\n","    </tr>\n","    <tr>\n","      <th>10795</th>\n","      <td>Don't waste it.</td>\n","      <td>\\t Ne le gaspille pas. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>21889</th>\n","      <td>Is this your car?</td>\n","      <td>\\t Est-ce votre voiture ? \\n</td>\n","    </tr>\n","    <tr>\n","      <th>12157</th>\n","      <td>Is this for me?</td>\n","      <td>\\t Est-ce que c'est pour moi ? \\n</td>\n","    </tr>\n","    <tr>\n","      <th>24487</th>\n","      <td>What's your name?</td>\n","      <td>\\t Comment tu t’appelles ? \\n</td>\n","    </tr>\n","    <tr>\n","      <th>29334</th>\n","      <td>That's pretty big.</td>\n","      <td>\\t C'est plutôt gros. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>19037</th>\n","      <td>You're generous.</td>\n","      <td>\\t Tu es généreux. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>12172</th>\n","      <td>It doesn't fit.</td>\n","      <td>\\t Ça ne convient pas. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>1123</th>\n","      <td>I hate it.</td>\n","      <td>\\t Je déteste ça. \\n</td>\n","    </tr>\n","    <tr>\n","      <th>22933</th>\n","      <td>That's too risky.</td>\n","      <td>\\t C'est trop risqué. \\n</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0a870b78-44b8-4dce-abef-29d1d055dc55')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0a870b78-44b8-4dce-abef-29d1d055dc55 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0a870b78-44b8-4dce-abef-29d1d055dc55');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-083c6cb6-b337-4875-bf2e-468515ca7e20\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-083c6cb6-b337-4875-bf2e-468515ca7e20')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-083c6cb6-b337-4875-bf2e-468515ca7e20 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"lines\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"src\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"I hate it.\",\n          \"Don't waste it.\",\n          \"That's pretty big.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tar\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"\\t Je d\\u00e9teste \\u00e7a. \\n\",\n          \"\\t Ne le gaspille pas. \\n\",\n          \"\\t C'est plut\\u00f4t gros. \\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["# 문자 집합 구축\n","src_vocab = set()\n","for line in lines.src: # 1줄씩 읽음\n","    for char in line: # 1개의 문자씩 읽음\n","        src_vocab.add(char)\n","\n","tar_vocab = set()\n","for line in lines.tar:\n","    for char in line:\n","        tar_vocab.add(char)\n","src_vocab_size = len(src_vocab)+1\n","tar_vocab_size = len(tar_vocab)+1\n","print('source 문장의 char 집합 :',src_vocab_size)\n","print('target 문장의 char 집합 :',tar_vocab_size)\n"],"metadata":{"id":"2rZibdEGM-9K","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716967192795,"user_tz":-540,"elapsed":5,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"b9674977-17c5-4b9e-b6d0-b9b7ef3ac4c0"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["source 문장의 char 집합 : 77\n","target 문장의 char 집합 : 102\n"]}]},{"cell_type":"code","source":["src_vocab = sorted(list(src_vocab))\n","tar_vocab = sorted(list(tar_vocab))\n","print(src_vocab[45:75])\n","print(tar_vocab[45:75])\n"],"metadata":{"id":"y-qwdJ-nNAIO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716967193266,"user_tz":-540,"elapsed":475,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"ef77fdaf-055e-4cb4-c466-2fe0eefb3f70"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["['W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n","['V', 'W', 'X', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"]}]},{"cell_type":"code","source":["src_to_index = dict([(word, i+1) for i, word in enumerate(src_vocab)])\n","tar_to_index = dict([(word, i+1) for i, word in enumerate(tar_vocab)])\n","print(src_to_index)\n","print(tar_to_index)"],"metadata":{"id":"B1UgHvDvNBQ4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716967193266,"user_tz":-540,"elapsed":3,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"894465b7-4992-4e23-e83b-c0a218dd3d94"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["{' ': 1, '!': 2, '\"': 3, '$': 4, '%': 5, '&': 6, \"'\": 7, ',': 8, '-': 9, '.': 10, '/': 11, '0': 12, '1': 13, '2': 14, '3': 15, '4': 16, '5': 17, '6': 18, '7': 19, '8': 20, '9': 21, ':': 22, '?': 23, 'A': 24, 'B': 25, 'C': 26, 'D': 27, 'E': 28, 'F': 29, 'G': 30, 'H': 31, 'I': 32, 'J': 33, 'K': 34, 'L': 35, 'M': 36, 'N': 37, 'O': 38, 'P': 39, 'Q': 40, 'R': 41, 'S': 42, 'T': 43, 'U': 44, 'V': 45, 'W': 46, 'X': 47, 'Y': 48, 'Z': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, 'é': 76}\n","{'\\t': 1, '\\n': 2, ' ': 3, '!': 4, '\"': 5, '$': 6, '%': 7, '&': 8, \"'\": 9, ',': 10, '-': 11, '.': 12, '0': 13, '1': 14, '2': 15, '3': 16, '4': 17, '5': 18, '6': 19, '7': 20, '8': 21, '9': 22, ':': 23, '?': 24, 'A': 25, 'B': 26, 'C': 27, 'D': 28, 'E': 29, 'F': 30, 'G': 31, 'H': 32, 'I': 33, 'J': 34, 'K': 35, 'L': 36, 'M': 37, 'N': 38, 'O': 39, 'P': 40, 'Q': 41, 'R': 42, 'S': 43, 'T': 44, 'U': 45, 'V': 46, 'W': 47, 'X': 48, 'Y': 49, 'a': 50, 'b': 51, 'c': 52, 'd': 53, 'e': 54, 'f': 55, 'g': 56, 'h': 57, 'i': 58, 'j': 59, 'k': 60, 'l': 61, 'm': 62, 'n': 63, 'o': 64, 'p': 65, 'q': 66, 'r': 67, 's': 68, 't': 69, 'u': 70, 'v': 71, 'w': 72, 'x': 73, 'y': 74, 'z': 75, '\\xa0': 76, '«': 77, '»': 78, 'À': 79, 'Ç': 80, 'É': 81, 'Ê': 82, 'Ô': 83, 'à': 84, 'â': 85, 'ç': 86, 'è': 87, 'é': 88, 'ê': 89, 'ë': 90, 'î': 91, 'ï': 92, 'ô': 93, 'ù': 94, 'û': 95, 'œ': 96, '\\u2009': 97, '‘': 98, '’': 99, '\\u202f': 100, '‽': 101}\n"]}]},{"cell_type":"code","source":["encoder_input = []\n","\n","# 1개의 문장\n","for line in lines.src:\n","  encoded_line = []\n","  # 각 줄에서 1개의 char\n","  for char in line:\n","    # 각 char을 정수로 변환\n","    encoded_line.append(src_to_index[char])\n","  encoder_input.append(encoded_line)\n","print('source 문장의 정수 인코딩 :',encoder_input[:5])\n"],"metadata":{"id":"5WW764AINCU-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716967193266,"user_tz":-540,"elapsed":2,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"c11d414d-df52-462c-bdae-0bbe6b70ef6a"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["source 문장의 정수 인코딩 : [[30, 64, 10], [30, 64, 10], [30, 64, 10], [30, 64, 10], [31, 58, 10]]\n"]}]},{"cell_type":"code","source":["decoder_input = []\n","for line in lines.tar:\n","  encoded_line = []\n","  for char in line:\n","    encoded_line.append(tar_to_index[char])\n","  decoder_input.append(encoded_line)\n","print('target 문장의 정수 인코딩 :',decoder_input[:5])\n"],"metadata":{"id":"hOOmmNN9NDlb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716967193706,"user_tz":-540,"elapsed":441,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"c9e228a1-cd6d-4c56-e744-cec527a26635"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["target 문장의 정수 인코딩 : [[1, 3, 46, 50, 3, 4, 3, 2], [1, 3, 37, 50, 67, 52, 57, 54, 12, 3, 2], [1, 3, 29, 63, 3, 67, 64, 70, 69, 54, 3, 4, 3, 2], [1, 3, 26, 64, 70, 56, 54, 3, 4, 3, 2], [1, 3, 43, 50, 61, 70, 69, 3, 4, 3, 2]]\n"]}]},{"cell_type":"code","source":["decoder_target = []\n","for line in lines.tar:\n","  timestep = 0\n","  encoded_line = []\n","  for char in line:\n","    if timestep > 0:\n","      encoded_line.append(tar_to_index[char])\n","    timestep = timestep + 1\n","  decoder_target.append(encoded_line)\n","print('target 문장 레이블의 정수 인코딩 :',decoder_target[:5])\n"],"metadata":{"id":"CvvpMMeLNE9r","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716967194552,"user_tz":-540,"elapsed":508,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"d757969b-8098-4d84-a3f5-5bb81f16b75e"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["target 문장 레이블의 정수 인코딩 : [[3, 46, 50, 3, 4, 3, 2], [3, 37, 50, 67, 52, 57, 54, 12, 3, 2], [3, 29, 63, 3, 67, 64, 70, 69, 54, 3, 4, 3, 2], [3, 26, 64, 70, 56, 54, 3, 4, 3, 2], [3, 43, 50, 61, 70, 69, 3, 4, 3, 2]]\n"]}]},{"cell_type":"code","source":["max_src_len = max([len(line) for line in lines.src])\n","max_tar_len = max([len(line) for line in lines.tar])\n","print('source 문장의 최대 길이 :',max_src_len)\n","print('target 문장의 최대 길이 :',max_tar_len)\n"],"metadata":{"id":"AONv69nINHMx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716967194552,"user_tz":-540,"elapsed":4,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"3b353f3a-2556-4b15-8e3f-ec246b943bd2"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["source 문장의 최대 길이 : 18\n","target 문장의 최대 길이 : 61\n"]}]},{"cell_type":"code","source":["encoder_input = pad_sequences(encoder_input, maxlen=max_src_len, padding='post')\n","decoder_input = pad_sequences(decoder_input, maxlen=max_tar_len, padding='post')\n","decoder_target = pad_sequences(decoder_target, maxlen=max_tar_len, padding='post')\n","encoder_input = to_categorical(encoder_input)\n","decoder_input = to_categorical(decoder_input)\n","decoder_target = to_categorical(decoder_target)\n"],"metadata":{"id":"zOh6zEstNIcN","executionInfo":{"status":"ok","timestamp":1716967196299,"user_tz":-540,"elapsed":728,"user":{"displayName":"헤헤","userId":"03480456663930627726"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["# Attention layer를 추가한 Seq2Seq 모델 학습해보기"],"metadata":{"id":"ybIq2SyJUk-0"}},{"cell_type":"code","source":["from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, LSTM, Dense, Concatenate, Dot, Activation, Lambda, Softmax\n","from tensorflow.keras.optimizers import RMSprop\n","import numpy as np\n","import tensorflow as tf"],"metadata":{"id":"NLLUpNPeNLlZ","executionInfo":{"status":"ok","timestamp":1716967196299,"user_tz":-540,"elapsed":2,"user":{"displayName":"헤헤","userId":"03480456663930627726"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# 어텐션 레이어\n","class AttentionLayer(tf.keras.layers.Layer):\n","    def __init__(self):\n","        super(AttentionLayer, self).__init__()\n","\n","    def call(self, query, key, value):\n","        scores = tf.matmul(query, key, transpose_b=True)\n","        attention_weights = Softmax(axis=-1)(scores)\n","        context_vector = tf.matmul(attention_weights, value)\n","        return context_vector, attention_weights"],"metadata":{"id":"SliYNzs2NOBD","executionInfo":{"status":"ok","timestamp":1716967196299,"user_tz":-540,"elapsed":1,"user":{"displayName":"헤헤","userId":"03480456663930627726"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# 인코더 정의\n","encoder_inputs = Input(shape=(None, src_vocab_size))\n","encoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n","encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n","\n","# 디코더 정의\n","decoder_inputs = Input(shape=(None, tar_vocab_size))\n","decoder_lstm = LSTM(256, return_sequences=True, return_state=True)\n","decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=[state_h, state_c])\n"],"metadata":{"id":"IWbDAxMJNupR","executionInfo":{"status":"ok","timestamp":1716967199216,"user_tz":-540,"elapsed":2360,"user":{"displayName":"헤헤","userId":"03480456663930627726"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["\n","# 어텐션 레이어 추가\n","# 1) AttentioLayer  선언\n","# 2) context_vector, attention_weights 에 출력 담기\n","attention_layer = AttentionLayer()\n","context_vector, attention_weights = attention_layer(decoder_outputs, encoder_outputs, encoder_outputs)\n","# 컨텍스트 벡터와 디코더 출력을 연결\n","decoder_concat_input = Concatenate(axis=-1)([context_vector, decoder_outputs])\n","\n","# 출력 레이어\n","decoder_dense = Dense(tar_vocab_size, activation='softmax')\n","decoder_outputs = decoder_dense(decoder_concat_input)\n","\n","# 전체 모델 정의\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","\n","# 모델 컴파일\n","model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# 모델 요약\n","model.summary()"],"metadata":{"id":"zkdhQz6uNwi8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716967273254,"user_tz":-540,"elapsed":15,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"bf712c46-2a97-4634-e298-370ba094d84d"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, None, 77)]           0         []                            \n","                                                                                                  \n"," input_2 (InputLayer)        [(None, None, 102)]          0         []                            \n","                                                                                                  \n"," lstm (LSTM)                 [(None, None, 256),          342016    ['input_1[0][0]']             \n","                              (None, 256),                                                        \n","                              (None, 256)]                                                        \n","                                                                                                  \n"," lstm_1 (LSTM)               [(None, None, 256),          367616    ['input_2[0][0]',             \n","                              (None, 256),                           'lstm[0][1]',                \n","                              (None, 256)]                           'lstm[0][2]']                \n","                                                                                                  \n"," attention_layer (Attention  ((None, None, 256),          0         ['lstm_1[0][0]',              \n"," Layer)                       (None, None, None))                    'lstm[0][0]',                \n","                                                                     'lstm[0][0]']                \n","                                                                                                  \n"," concatenate_1 (Concatenate  (None, None, 512)            0         ['attention_layer[0][0]',     \n"," )                                                                   'lstm_1[0][0]']              \n","                                                                                                  \n"," dense (Dense)               (None, None, 102)            52326     ['concatenate_1[0][0]']       \n","                                                                                                  \n","==================================================================================================\n","Total params: 761958 (2.91 MB)\n","Trainable params: 761958 (2.91 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# 모델 학습\n","model.fit(\n","    [encoder_input, decoder_input],\n","    decoder_target,\n","    batch_size=64,\n","    epochs=40,\n","    validation_split=0.2\n",")\n","\n"],"metadata":{"id":"Bu1uJuRXNz8b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716967485432,"user_tz":-540,"elapsed":207409,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"1cc57d00-6314-494c-8ff2-a110eff65e0b"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/40\n","375/375 [==============================] - 11s 20ms/step - loss: 1.1321 - accuracy: 0.7110 - val_loss: 0.9983 - val_accuracy: 0.7172\n","Epoch 2/40\n","375/375 [==============================] - 4s 12ms/step - loss: 0.7508 - accuracy: 0.7828 - val_loss: 0.8308 - val_accuracy: 0.7554\n","Epoch 3/40\n","375/375 [==============================] - 4s 12ms/step - loss: 0.6428 - accuracy: 0.8119 - val_loss: 0.7373 - val_accuracy: 0.7817\n","Epoch 4/40\n","375/375 [==============================] - 5s 15ms/step - loss: 0.5868 - accuracy: 0.8267 - val_loss: 0.6870 - val_accuracy: 0.7939\n","Epoch 5/40\n","375/375 [==============================] - 5s 14ms/step - loss: 0.5473 - accuracy: 0.8376 - val_loss: 0.6449 - val_accuracy: 0.8079\n","Epoch 6/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.5147 - accuracy: 0.8470 - val_loss: 0.6156 - val_accuracy: 0.8169\n","Epoch 7/40\n","375/375 [==============================] - 5s 14ms/step - loss: 0.4871 - accuracy: 0.8551 - val_loss: 0.5860 - val_accuracy: 0.8250\n","Epoch 8/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.4639 - accuracy: 0.8615 - val_loss: 0.5674 - val_accuracy: 0.8301\n","Epoch 9/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.4444 - accuracy: 0.8673 - val_loss: 0.5516 - val_accuracy: 0.8339\n","Epoch 10/40\n","375/375 [==============================] - 7s 18ms/step - loss: 0.4274 - accuracy: 0.8722 - val_loss: 0.5339 - val_accuracy: 0.8403\n","Epoch 11/40\n","375/375 [==============================] - 5s 13ms/step - loss: 0.4117 - accuracy: 0.8767 - val_loss: 0.5207 - val_accuracy: 0.8442\n","Epoch 12/40\n","375/375 [==============================] - 5s 15ms/step - loss: 0.3981 - accuracy: 0.8809 - val_loss: 0.5083 - val_accuracy: 0.8476\n","Epoch 13/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.3855 - accuracy: 0.8846 - val_loss: 0.5006 - val_accuracy: 0.8510\n","Epoch 14/40\n","375/375 [==============================] - 4s 12ms/step - loss: 0.3740 - accuracy: 0.8880 - val_loss: 0.4847 - val_accuracy: 0.8560\n","Epoch 15/40\n","375/375 [==============================] - 6s 15ms/step - loss: 0.3640 - accuracy: 0.8911 - val_loss: 0.4765 - val_accuracy: 0.8588\n","Epoch 16/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.3542 - accuracy: 0.8939 - val_loss: 0.4676 - val_accuracy: 0.8614\n","Epoch 17/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.3455 - accuracy: 0.8965 - val_loss: 0.4628 - val_accuracy: 0.8630\n","Epoch 18/40\n","375/375 [==============================] - 5s 14ms/step - loss: 0.3373 - accuracy: 0.8989 - val_loss: 0.4566 - val_accuracy: 0.8653\n","Epoch 19/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.3295 - accuracy: 0.9012 - val_loss: 0.4518 - val_accuracy: 0.8661\n","Epoch 20/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.3222 - accuracy: 0.9032 - val_loss: 0.4484 - val_accuracy: 0.8679\n","Epoch 21/40\n","375/375 [==============================] - 6s 15ms/step - loss: 0.3153 - accuracy: 0.9052 - val_loss: 0.4393 - val_accuracy: 0.8709\n","Epoch 22/40\n","375/375 [==============================] - 4s 12ms/step - loss: 0.3086 - accuracy: 0.9074 - val_loss: 0.4376 - val_accuracy: 0.8712\n","Epoch 23/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.3022 - accuracy: 0.9092 - val_loss: 0.4354 - val_accuracy: 0.8718\n","Epoch 24/40\n","375/375 [==============================] - 5s 14ms/step - loss: 0.2964 - accuracy: 0.9108 - val_loss: 0.4306 - val_accuracy: 0.8731\n","Epoch 25/40\n","375/375 [==============================] - 4s 12ms/step - loss: 0.2907 - accuracy: 0.9126 - val_loss: 0.4305 - val_accuracy: 0.8733\n","Epoch 26/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.2851 - accuracy: 0.9141 - val_loss: 0.4267 - val_accuracy: 0.8748\n","Epoch 27/40\n","375/375 [==============================] - 5s 14ms/step - loss: 0.2800 - accuracy: 0.9156 - val_loss: 0.4269 - val_accuracy: 0.8754\n","Epoch 28/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.2750 - accuracy: 0.9170 - val_loss: 0.4219 - val_accuracy: 0.8766\n","Epoch 29/40\n","375/375 [==============================] - 4s 12ms/step - loss: 0.2701 - accuracy: 0.9184 - val_loss: 0.4221 - val_accuracy: 0.8769\n","Epoch 30/40\n","375/375 [==============================] - 6s 15ms/step - loss: 0.2654 - accuracy: 0.9199 - val_loss: 0.4239 - val_accuracy: 0.8772\n","Epoch 31/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.2608 - accuracy: 0.9211 - val_loss: 0.4220 - val_accuracy: 0.8771\n","Epoch 32/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.2563 - accuracy: 0.9226 - val_loss: 0.4209 - val_accuracy: 0.8784\n","Epoch 33/40\n","375/375 [==============================] - 5s 14ms/step - loss: 0.2523 - accuracy: 0.9236 - val_loss: 0.4216 - val_accuracy: 0.8791\n","Epoch 34/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.2479 - accuracy: 0.9249 - val_loss: 0.4192 - val_accuracy: 0.8795\n","Epoch 35/40\n","375/375 [==============================] - 5s 14ms/step - loss: 0.2440 - accuracy: 0.9261 - val_loss: 0.4207 - val_accuracy: 0.8796\n","Epoch 36/40\n","375/375 [==============================] - 5s 14ms/step - loss: 0.2401 - accuracy: 0.9271 - val_loss: 0.4193 - val_accuracy: 0.8803\n","Epoch 37/40\n","375/375 [==============================] - 4s 12ms/step - loss: 0.2362 - accuracy: 0.9281 - val_loss: 0.4220 - val_accuracy: 0.8798\n","Epoch 38/40\n","375/375 [==============================] - 5s 14ms/step - loss: 0.2326 - accuracy: 0.9294 - val_loss: 0.4228 - val_accuracy: 0.8804\n","Epoch 39/40\n","375/375 [==============================] - 5s 13ms/step - loss: 0.2288 - accuracy: 0.9304 - val_loss: 0.4191 - val_accuracy: 0.8807\n","Epoch 40/40\n","375/375 [==============================] - 5s 12ms/step - loss: 0.2253 - accuracy: 0.9314 - val_loss: 0.4225 - val_accuracy: 0.8806\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7af07a300c10>"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["index_to_src = dict((i, char) for char, i in src_to_index.items())\n","index_to_tar = dict((i, char) for char, i in tar_to_index.items())\n"],"metadata":{"id":"kPIrjojKUaQO","executionInfo":{"status":"ok","timestamp":1716967833944,"user_tz":-540,"elapsed":521,"user":{"displayName":"헤헤","userId":"03480456663930627726"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["# 인코더 모델\n","encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])\n","\n","# 디코더\n","# 입력 정의\n","decoder_state_input_h = Input(shape=(256,), name=\"decoder_state_input_h\")\n","decoder_state_input_c = Input(shape=(256,), name=\"decoder_state_input_c\")\n","\n","# 디코더 LSTM\n","decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=[decoder_state_input_h, decoder_state_input_c])\n","\n","# 어텐션 레이어 추가\n","context_vector, attention_weights = attention_layer(decoder_outputs, encoder_outputs, encoder_outputs)\n","\n","# 컨텍스트 벡터와 디코더 출력을 결합\n","decoder_concat_input = Concatenate(name=\"concatenate_layer\")([context_vector, decoder_outputs])\n","\n","# 최종 출력 레이어\n","decoder_final_output = decoder_dense(decoder_concat_input)\n","\n","# 디코더 모델 생성\n","decoder_model = Model(\n","    inputs=[decoder_inputs, encoder_outputs, decoder_state_input_h, decoder_state_input_c],\n","    outputs=[decoder_final_output, state_h, state_c, attention_weights]\n",")\n","\n","\n","# 오류 메시지에 나타난 문제를 디버깅하기 위해 모델의 개요를 출력\n","encoder_model.summary()\n","decoder_model.summary()\n","\n"],"metadata":{"id":"2HOlvfvMU_GL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1716967836195,"user_tz":-540,"elapsed":12,"user":{"displayName":"헤헤","userId":"03480456663930627726"}},"outputId":"a99d1164-cf24-4394-e25a-f83ec2672978"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, None, 77)]        0         \n","                                                                 \n"," lstm (LSTM)                 [(None, None, 256),       342016    \n","                              (None, 256),                       \n","                              (None, 256)]                       \n","                                                                 \n","=================================================================\n","Total params: 342016 (1.30 MB)\n","Trainable params: 342016 (1.30 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","Model: \"model_2\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_2 (InputLayer)        [(None, None, 102)]          0         []                            \n","                                                                                                  \n"," decoder_state_input_h (Inp  [(None, 256)]                0         []                            \n"," utLayer)                                                                                         \n","                                                                                                  \n"," decoder_state_input_c (Inp  [(None, 256)]                0         []                            \n"," utLayer)                                                                                         \n","                                                                                                  \n"," lstm_1 (LSTM)               [(None, None, 256),          367616    ['input_2[0][0]',             \n","                              (None, 256),                           'decoder_state_input_h[0][0]'\n","                              (None, 256)]                          , 'decoder_state_input_c[0][0]\n","                                                                    ']                            \n","                                                                                                  \n"," input_3 (InputLayer)        [(None, None, 256)]          0         []                            \n","                                                                                                  \n"," attention_layer (Attention  ((None, None, 256),          0         ['lstm_1[2][0]',              \n"," Layer)                       (None, None, None))                    'input_3[0][0]',             \n","                                                                     'input_3[0][0]']             \n","                                                                                                  \n"," concatenate_layer (Concate  (None, None, 512)            0         ['attention_layer[2][0]',     \n"," nate)                                                               'lstm_1[2][0]']              \n","                                                                                                  \n"," dense (Dense)               (None, None, 102)            52326     ['concatenate_layer[1][0]']   \n","                                                                                                  \n","==================================================================================================\n","Total params: 419942 (1.60 MB)\n","Trainable params: 419942 (1.60 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["\n","# 번역 결과를 디코딩하는 함수\n","def decode_sequence(input_seq):\n","    # 인코더의 상태를 얻음\n","    encoder_output, state_h, state_c = encoder_model.predict(input_seq)\n","\n","    # 디코더의 초기 입력 (시작 심볼)\n","    target_seq = np.zeros((1, 1, tar_vocab_size))\n","    target_seq[0, 0, tar_to_index['\\t']] = 1.\n","\n","    # 디코딩 루프\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition:\n","        output_tokens, h, c, a = decoder_model.predict([target_seq, encoder_output, state_h, state_c])\n","\n","        # 샘플링\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_char = index_to_tar[sampled_token_index]\n","        decoded_sentence += sampled_char\n","\n","        # 종료 조건: 최대 길이 초과 또는 종료 심볼\n","        if (sampled_char == '\\n' or len(decoded_sentence) > max_tar_len):\n","            stop_condition = True\n","\n","        # 다음 디코더 입력 업데이트\n","        target_seq = np.zeros((1, 1, tar_vocab_size))\n","        target_seq[0, 0, sampled_token_index] = 1.\n","\n","        # 상태 업데이트\n","        state_h, state_c = h, c\n","\n","    return decoded_sentence"],"metadata":{"id":"wC1yCZVkVVO2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 테스트 데이터 사용 예시\n","for seq_index in [3,50,100,300,1001]: # 입력 문장의 인덱스\n","  input_seq = encoder_input[seq_index:seq_index+1]\n","  decoded_sentence = decode_sequence(input_seq)\n","  print(35 * \"-\")\n","  print('입력 문장:', lines.src[seq_index])\n","  print('정답 문장:', lines.tar[seq_index][2:len(lines.tar[seq_index])-1]) # '\\t'와 '\\n'을 빼고 출력\n","  print('번역 문장:', decoded_sentence[1:len(decoded_sentence)-1]) # '\\n'을 빼고 출력\n"],"metadata":{"id":"y5VvDPvnOwSk"},"execution_count":null,"outputs":[]}]}